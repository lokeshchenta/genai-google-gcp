{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uj7R48-ZXmTC",
    "tags": []
   },
   "source": [
    "# GenAI ChatBot for Enterprise Data Using Retrieval Augmented Generation (RAG)\n",
    "### Built on Google's GCP Vertex AI platform, using Gemini Models\n",
    "### Uses GCS (for Document storage), LangChain (for building RAG system), Redis (for Vector DB)\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPG8eRQCcNQ3"
   },
   "source": [
    "## Installation & Authentication\n",
    "\n",
    "Install LangChain, Vertex AI LLM SDK, and related libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IdsE3DEJcM35",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install google-cloud-aiplatform langchain unstructured unstructured[pdf] --upgrade --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U langchain-community langchain-google-community langchain-google-vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "XRvKdaPDTznN",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restart kernel after installs so that your environment can access the new packages\n",
    "\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbmM4z7FOBpM"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8a1cc7ca1e0d"
   },
   "source": [
    "## Get Libraries & Classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ax6hlCt7YbXx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from langchain_google_community import GCSDirectoryLoader\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from langchain_google_vertexai import VertexAI\n",
    "\n",
    "# Using Vertex AI\n",
    "import vertexai\n",
    "\n",
    "# print(f\"Vertex AI SDK version: {aiplatform.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yHf4ipxYyfy"
   },
   "source": [
    "## Initialize Vertex AI\n",
    "\n",
    "**We will need a project id and location where the Vertex AI compute and embedding will be hosted**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT_ID = \"[your-project-id]\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
    "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
    "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YozENqoAmm9"
   },
   "source": [
    "## Ingest the Documents to build the context for the LLM\n",
    "\n",
    "_Load all the Documents from Google Cloud Storage (GCS Bucket)_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Td4rD2MQtM1O",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of documents = 2\n"
     ]
    }
   ],
   "source": [
    "loader = GCSDirectoryLoader(\n",
    "    project_name=PROJECT_ID, bucket=\"rag-langchain-demo\"\n",
    ")\n",
    "documents = loader.load()\n",
    "print(f\"No. of documents = {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Da7_1bpFGpb"
   },
   "source": [
    "_Split documents into chunks as needed by the token limit of the LLM and let there be an overlap between the chunks_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2E_qzSuMFHKt",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of document chunks = 125\n"
     ]
    }
   ],
   "source": [
    "# split the documents into chunks\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=100)\n",
    "doc_chunks = text_splitter.split_documents(documents)\n",
    "print(f\"No. of document chunks = {len(doc_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0htdnYAHonv"
   },
   "source": [
    "## Structuring the ingested documents in a vector space using Redis as Vector Database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuwJlBNwIy0y"
   },
   "source": [
    "_Create an embedding vector engine for all the text in the documents that have been ingested_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_nNWJ6XaH1fa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Text Embeddings model\n",
    "embeddings_model = VertexAIEmbeddings(project=PROJECT_ID, location=LOCATION, model_name=\"text-embedding-005\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_A6JEaReI96b"
   },
   "source": [
    "_Create a vector store and store the embeddings in the vector store_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Replace values below with your own if using Redis Cloud instance\n",
    "REDIS_HOST = os.getenv(\"REDIS_HOST\", \"127.0.0.1\") \n",
    "REDIS_PORT = os.getenv(\"REDIS_PORT\", \"6379\")      \n",
    "REDIS_URL = f\"redis://{REDIS_HOST}:{REDIS_PORT}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import redis\n",
    "\n",
    "# Connect with the Redis Python Client\n",
    "client = redis.Redis.from_url(REDIS_URL)\n",
    "client.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install langchain-google-memorystore-redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain_google_memorystore_redis import (\n",
    "    DistanceStrategy,\n",
    "    HNSWConfig,\n",
    "    RedisVectorStore,\n",
    ")\n",
    "\n",
    "index_config = HNSWConfig(\n",
    "    name=\"public_rag_demo\", distance_strategy=DistanceStrategy.COSINE, vector_size=768\n",
    ")\n",
    "\n",
    "try:\n",
    "    RedisVectorStore.init_index(client=client, index_config=index_config)\n",
    "except redis.exceptions.ResponseError as e:\n",
    "    if re.match(r\".*already exists\", str(e)):\n",
    "        print(\"Index already exists, skipping creation.\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "redis_vector_db = RedisVectorStore(\n",
    "    index_name=\"public_rag_demo\",\n",
    "    embeddings=embeddings_model,\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['public_rag_demo72b0d9b0-0976-43db-9ad9-66da2328bd82',\n",
       " 'public_rag_demob4445ca9-6342-4e45-8463-9c2e0eabb8ca',\n",
       " 'public_rag_demo9b8d59aa-0b3f-496c-be7d-5db9ba5f8ebb',\n",
       " 'public_rag_demo05340896-f976-4661-8518-f5171fc28f76',\n",
       " 'public_rag_demoe1915047-0288-48d1-8e5d-74682fa7bd24',\n",
       " 'public_rag_demoe3f32cbf-534f-4455-921f-9cf6322e923a',\n",
       " 'public_rag_demo5f2d2f66-0e03-4fec-8930-8e321eca1458',\n",
       " 'public_rag_demoad3f1ed3-5bde-450d-a9c6-9b10af14e629',\n",
       " 'public_rag_demo69bab5b0-fd37-4b29-9704-396487208778',\n",
       " 'public_rag_demo3d405d45-a088-4a86-8eff-01698041508c',\n",
       " 'public_rag_demo44680270-52e4-41b5-a522-af5ce591de86',\n",
       " 'public_rag_demo31e97098-d47c-4773-aead-db6756bee8bb',\n",
       " 'public_rag_democ7f78586-05a8-453f-b2cf-4bb22c178a7c',\n",
       " 'public_rag_demo94e626ce-52db-4d99-8c75-89e2248ef3be',\n",
       " 'public_rag_democacc4099-bcfa-48b6-8e7d-e3c68ffd41e0',\n",
       " 'public_rag_demo365cce0f-6bf3-4bb7-b3dd-0b62ccef531f',\n",
       " 'public_rag_demof76c4699-d06b-479d-8e5a-f09cb45300b8',\n",
       " 'public_rag_demo675b507f-fc42-4527-b17a-3633a64da021',\n",
       " 'public_rag_demo5dc2637a-bc47-4f67-ac04-540f32400dd7',\n",
       " 'public_rag_demo4c0d7093-772e-4877-8ba0-b570bc1ebf72',\n",
       " 'public_rag_demo46144920-dc06-46e6-81cb-50d405a6d77a',\n",
       " 'public_rag_demo8ec45587-24cd-41bd-8604-5bb9a1c4fd96',\n",
       " 'public_rag_demoe80c708a-16ad-4372-abfc-2d3373bf4f4b',\n",
       " 'public_rag_democf75dd8e-4bf1-4650-a324-cf477ab7dd63',\n",
       " 'public_rag_demo204a7d81-8529-4e17-b12b-549a93c2d07e',\n",
       " 'public_rag_demo1defa1d2-f9db-4119-afb6-118b983764f1',\n",
       " 'public_rag_democf2dafbc-e2ce-4628-8af2-a372f11d3acb',\n",
       " 'public_rag_demo1f688135-43a3-44a1-ae1e-afb2b71023d9',\n",
       " 'public_rag_demoabf72bcc-9dac-4f2c-b163-cd5a84e278e0',\n",
       " 'public_rag_democc33f897-0bca-4676-bd61-48e8fab05ee6',\n",
       " 'public_rag_demoa2f76cba-ca1e-413b-9a47-e0c94babd7bf',\n",
       " 'public_rag_demo36d73b90-12cd-4fbf-81ac-dfba30a064b0',\n",
       " 'public_rag_demo79ded280-2c47-4a97-8b99-18d582b9c35e',\n",
       " 'public_rag_demoebf1388e-cfe8-4155-bb99-06475a9959ea',\n",
       " 'public_rag_demo816c1195-ef9e-41e2-a264-d8c40adce7b3',\n",
       " 'public_rag_demoec6adf15-4cee-4bd1-a589-597e229e61e5',\n",
       " 'public_rag_demoa4ee3b3a-75e8-406e-aa35-64751eda6483',\n",
       " 'public_rag_demoaf4ca0fb-60a4-4332-9bb8-6629d2f31a1f',\n",
       " 'public_rag_demo20a420e8-76f0-4915-af90-c117ca712e1f',\n",
       " 'public_rag_demo09ff3b5b-6dfa-4634-981f-6d4a49cf8fc8',\n",
       " 'public_rag_demof4dd2450-7544-4230-95f6-3d8d3fbbbba6',\n",
       " 'public_rag_demo0bff8f98-9687-4f72-8be7-7f004fa1be98',\n",
       " 'public_rag_demod6ea80e5-c590-43e4-8fc8-b58c704d9ce7',\n",
       " 'public_rag_demo6632224f-6f1d-45c1-9d9a-7125414b1807',\n",
       " 'public_rag_demo0af221d2-35da-43f4-85ad-9d408719e1f0',\n",
       " 'public_rag_demo9f8109fc-1faf-45b5-8a1f-fbf6d0c310ce',\n",
       " 'public_rag_demo59e12ea2-8065-4602-9766-92e4569d66a9',\n",
       " 'public_rag_democ09b644b-62fd-4d73-9ceb-873acaf82d25',\n",
       " 'public_rag_demo7969a475-216e-4db4-ad5f-d8e9fc715d55',\n",
       " 'public_rag_demoa10a76e3-4c4d-4009-a45f-4c8ed93cc1b8',\n",
       " 'public_rag_demo00293a92-ca55-4a85-8c91-97981b850ec5',\n",
       " 'public_rag_demo9ee44295-45f0-4bf3-87ed-bd427ef8b507',\n",
       " 'public_rag_demod3b7214c-94b9-4eb4-8898-a79d8a60bfd0',\n",
       " 'public_rag_demo160a8d78-ad50-43dc-884c-cf19cb0203f2',\n",
       " 'public_rag_demof360d057-83c9-4a55-a8ef-dba92adcadf0',\n",
       " 'public_rag_demod7da1015-c7c9-4222-b23d-d37e67466ed2',\n",
       " 'public_rag_democ2d6587f-81e9-4049-9c88-81c2acaf737a',\n",
       " 'public_rag_demo222ecad7-33e7-4b0e-9a78-4a2c83a68054',\n",
       " 'public_rag_demoa74f4360-5817-4cbc-8fc2-6c4f638f9777',\n",
       " 'public_rag_demo1bbfea8e-d5e1-4047-a6fe-6a233c8f5978',\n",
       " 'public_rag_demo18af8cb0-983c-4c07-8885-a34a31dd4ec3',\n",
       " 'public_rag_demo314f9f28-e1b3-4e78-a9f7-2c4552913ef4',\n",
       " 'public_rag_demofa13e406-dae7-4a46-91d4-218c8813f31c',\n",
       " 'public_rag_demo6bbd7947-b9a0-41f7-a5d3-c124cc46fd2b',\n",
       " 'public_rag_demo87082d63-8703-46e4-8e96-45975931f2c8',\n",
       " 'public_rag_demo49193c18-bb75-45e2-b021-975fd59dc4da',\n",
       " 'public_rag_demo31630745-95c9-486c-87b4-6a3a30049756',\n",
       " 'public_rag_demo7963690f-13bf-409b-8498-f07cc60e1df9',\n",
       " 'public_rag_demo15fc486e-ccf5-4880-91af-4ae16076a337',\n",
       " 'public_rag_demoe7f82938-4f8d-4406-8b93-0c687ef9a0e7',\n",
       " 'public_rag_demo674de16f-ec17-4341-86b8-e5ef28dd466c',\n",
       " 'public_rag_demo27c5cc2c-8962-4393-ac47-2e4c2a4fb1ad',\n",
       " 'public_rag_demoa3a20817-eaa6-4916-9328-7b54d8b9c14e',\n",
       " 'public_rag_demodbaf93ec-8b4c-4cee-b2c7-902a35fad4be',\n",
       " 'public_rag_demo2868b213-46d4-44ce-9f36-2ebffbbf700f',\n",
       " 'public_rag_demoa19af908-2113-45f7-a045-a45e89681b8e',\n",
       " 'public_rag_demof52aceb0-3850-406b-b479-936dfb612973',\n",
       " 'public_rag_demoefa722b2-fb3e-4aaf-9e58-e4e28e5916a6',\n",
       " 'public_rag_demo0d76b066-d898-4b82-8bc8-5dea1ce84c31',\n",
       " 'public_rag_demoe6d8f17a-5542-471a-9154-faab9ee8b88b',\n",
       " 'public_rag_demo84207d87-edd4-4309-9b88-632ce549b2c4',\n",
       " 'public_rag_demo1a0349c0-0fb3-451f-9418-fcad12226f55',\n",
       " 'public_rag_demo8d0ea0f5-7efb-4472-be66-98abb4beac5a',\n",
       " 'public_rag_demo337e9ed6-d866-4bef-9e9c-a9f65d83cfa2',\n",
       " 'public_rag_demobe95f155-ca15-42ce-b120-87fecba26e07',\n",
       " 'public_rag_demo96677582-1e04-4384-9921-f1896caa5991',\n",
       " 'public_rag_demoa60e57ac-c9b5-444a-b765-d7addb7b9c7a',\n",
       " 'public_rag_demoaa3f7f92-5ed3-4e6f-9731-60e25375c501',\n",
       " 'public_rag_demo423faa31-ce75-419d-8346-da47a5f660a3',\n",
       " 'public_rag_demo9dfbc21d-4d0a-46c9-be6d-d1843063be50',\n",
       " 'public_rag_demo397aaeff-70d1-42d6-9252-be941492daed',\n",
       " 'public_rag_demoe87cfbb7-aea8-4f61-b374-d39afacb5331',\n",
       " 'public_rag_demo58a340e5-5055-4366-b92d-a8fbd96e3971',\n",
       " 'public_rag_demo25550c66-c321-424e-9538-06f1b8f916bf',\n",
       " 'public_rag_demo7b3fd7ca-1d2e-4bc0-ac7f-c0dbc51657fd',\n",
       " 'public_rag_demof68e091b-ceb0-4ab7-b5fa-cb439686c664',\n",
       " 'public_rag_demo6a503429-ded1-474c-bf0f-1428f0074e85',\n",
       " 'public_rag_demoed5a1c33-d16a-4218-bd11-21397eca98da',\n",
       " 'public_rag_demo7d15ba81-148c-4e3b-b97d-d5c1f222eacf',\n",
       " 'public_rag_demoa643a25d-9b58-4d04-b47d-facc0abcd01f',\n",
       " 'public_rag_demoabd4adf7-423a-43b3-97ad-109abc707b5a',\n",
       " 'public_rag_democcbad984-6b29-47cd-a3ac-97f5297c9703',\n",
       " 'public_rag_demo1f70076e-78fa-4cf7-bd15-e5ab1b6466b4',\n",
       " 'public_rag_demo623e39e5-c2bb-4112-9650-db26f5489cd2',\n",
       " 'public_rag_demoe70bd100-a53c-41e1-8cc9-58702f0d540d',\n",
       " 'public_rag_demo87e3fb9a-90b9-4ba0-8925-fa148d89a482',\n",
       " 'public_rag_demo02ff56b8-546d-4923-b82f-f8afa848454a',\n",
       " 'public_rag_demo4c003016-0614-4939-8272-2b2375b0ce3c',\n",
       " 'public_rag_democ9b4c302-790a-4fc7-821c-c41e395fde41',\n",
       " 'public_rag_demodb8a2dff-ca2c-49d4-bd9f-362651afe672',\n",
       " 'public_rag_demoa6161d9e-c13a-4b48-81bd-dc357b214585',\n",
       " 'public_rag_demof4ae6f48-02f9-4ef4-82e6-b0c5a6b0ba51',\n",
       " 'public_rag_demodee4b172-d1cc-4e3f-9d9f-f19673c3a348',\n",
       " 'public_rag_demoe9e36b79-9cec-403a-93bf-32ee1333f641',\n",
       " 'public_rag_demofdb0868a-780a-47ca-9410-89e07c844ace',\n",
       " 'public_rag_demof09fbdd6-22eb-46d7-a6ab-33124a9d87d3',\n",
       " 'public_rag_demo5b46ebf4-3ab1-4860-99bb-5444915d8642',\n",
       " 'public_rag_demo665fc568-0819-4d91-b303-672363a365c5',\n",
       " 'public_rag_democ5addc88-a934-46d5-ab8c-a4e3abba75d1',\n",
       " 'public_rag_demoe7f70b44-fa7f-483e-ace8-60d10cfa468b',\n",
       " 'public_rag_demob5a87cb7-b8c0-4ea5-87cc-92360ded592d',\n",
       " 'public_rag_demo147f6b76-6d65-40cb-9364-3d83333ebcb9',\n",
       " 'public_rag_demo25240915-1dea-4280-905b-b4439f6d7be5',\n",
       " 'public_rag_demo5b4f14a5-0ea1-4dbc-beb0-afddcf72702d',\n",
       " 'public_rag_demo296efc9e-44d0-40dc-bb97-3a59121d384d']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redis_vector_db.add_documents(doc_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVCftNbU-wp0"
   },
   "source": [
    "## Obtain handle to the retriever\n",
    "\n",
    "We will use the native retriever to perform similarity search within the vector store among the different document chunks so as to return that document chunk which has the lowest vectoral \"distance\" with the incoming user query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Xb2VCn6e-0zp",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['RedisVectorStore'], vectorstore=<langchain_google_memorystore_redis.vectorstore.RedisVectorStore object at 0x7fdfc14ccfa0>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expose index to the retriever\n",
    "retriever = redis_vector_db.as_retriever(\n",
    "    search_type=\"similarity\", search_kwargs={\"k\": 3}\n",
    ")\n",
    "retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QcwQNvfN_6Rn"
   },
   "source": [
    "## Define a Retrieval QA Chain to use retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ElWUO3fQAMaH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We use Vertex AI Gemini Flash for LLM\n",
    "llm = VertexAI(\n",
    "    project=PROJECT_ID, \n",
    "    location=LOCATION, \n",
    "    model_name=\"gemini-2.0-flash\",\n",
    "    max_output_tokens=1000,\n",
    "    temperature=0.05,\n",
    "    top_p=0.8,\n",
    "    top_k=40,\n",
    "    verbose=True\n",
    ")\n",
    "#llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ElWUO3fQAMaH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create chain to answer questions\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Uses LLM to synthesize results from the search index.\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHYlgYQhFTQW"
   },
   "source": [
    "## Leverage LLM to search from retriever\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUZDkQOrGb9X"
   },
   "source": [
    "_Example:_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the profit of Uber in 2023? Give revenue, profit details\n",
      "Response:\n",
      " Based on the provided text:\n",
      "\n",
      "*   **Revenue:** $37.3 billion\n",
      "*   **Net income attributable to Uber Technologies, Inc.:** $1.9 billion\n",
      "*   **Adjusted EBITDA:** $4.1 billion\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the profit of Uber in 2023? Give revenue, profit details\"\n",
    "results = qa({\"query\": query})\n",
    "print(\"Query:\", query)\n",
    "print(\"Response:\\n\", results['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the increase in profit of Google in 2024 compared to 2023 ?\n",
      "Response:\n",
      " Google Services operating income increased $25.4 billion from 2023 to 2024 and Google Cloud operating income increased $4.4 billion from 2023 to 2024. The combined increase in profit of Google Services and Google Cloud in 2024 compared to 2023 is $29.8 billion.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the increase in profit of Google in 2024 compared to 2023 ?\"\n",
    "results = qa({\"query\": query})\n",
    "print(\"Query:\", query)\n",
    "print(\"Response:\\n\", results['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the profit of Ola in 2024?\n",
      "Response:\n",
      " I'm sorry, but I cannot answer the question about Ola's profit in 2024. The provided text does not contain any information about Ola's financial performance. It focuses on Uber's performance and investments.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the profit of Ola in 2024?\"\n",
    "results = qa({\"query\": query})\n",
    "print(\"Query:\", query)\n",
    "print(\"Response:\\n\", results['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How many employees are there in Uber?\n",
      "Response:\n",
      " As of December 31, 2023, Uber and its subsidiaries had approximately 30,400 employees globally.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"How many employees are there in Uber?\"\n",
    "results = qa({\"query\": query})\n",
    "print(\"Query:\", query)\n",
    "print(\"Response:\\n\", results['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the revenue of Alphabet in 2024? What is the increase compared to 2023\n",
      "Response:\n",
      " The revenue of Alphabet in 2024 was $350.018 billion. The increase compared to 2023 was $42.624 billion.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the revenue of Alphabet in 2024? What is the increase compared to 2023\"\n",
    "results = qa({\"query\": query})\n",
    "print(\"Query:\", query)\n",
    "print(\"Response:\\n\", results['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgYa4k1WiolM"
   },
   "source": [
    "## Build a Front End\n",
    "\n",
    "Enable a simple front end so users can query against documents and obtain intelligent answers with grounding information that references the base documents that was used to respond to user query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "4a84715c549d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "CRjBQsXqirbC",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/gradio/blocks.py:1117: UserWarning: Theme should be a class loaded from gradio.themes\n",
      "  warnings.warn(\"Theme should be a class loaded from gradio.themes\")\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "def chatbot(input_text):\n",
    "    result = qa({\"query\": input_text})\n",
    "\n",
    "    return (\n",
    "        result[\"result\"],\n",
    "        get_public_url(result[\"source_documents\"][0].metadata[\"source\"]),\n",
    "        result[\"source_documents\"][0].metadata[\"source\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def get_public_url(uri):\n",
    "    \"\"\"Returns the public URL for a file in Google Cloud Storage.\"\"\"\n",
    "    # Split the URI into its components\n",
    "    components = uri.split(\"/\")\n",
    "\n",
    "    # Get the bucket name\n",
    "    bucket_name = components[2]\n",
    "\n",
    "    # Get the file name\n",
    "    file_name = components[3]\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(file_name)\n",
    "    return blob.public_url\n",
    "\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=chatbot,\n",
    "    inputs=[gr.Textbox(label=\"Query\")],\n",
    "    title=\"Enterprise Data Search ChatBot\",\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Response\"),\n",
    "        gr.Textbox(label=\"URL\"),\n",
    "        gr.Textbox(label=\"Cloud Storage URI\"),\n",
    "    ],\n",
    "    theme=gr.themes.Soft,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "CRjBQsXqirbC",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Gradio\n",
      "Rerunning server... use `close()` to stop if you need to change `launch()` parameters.\n",
      "----\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Launching Gradio\")\n",
    "\n",
    "iface.launch(share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "contract_analysis.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
